{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche du meillieur algo ML - Entranement test - pipeline¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des bibliothèques nécéssaires\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour le chargement du dataSet à partir du fichier CSV\n",
    "def train_test_split_fonction(method, filename):\n",
    "    df= pd.read_csv(filename, sep=';')\n",
    "    \n",
    "    #  Sous_échantillonnage (Under-Sampling) des données pour avoir un DataSet équilibré\n",
    "    #nombre de négatif \n",
    "    no_negatif = len(df[df['Sentiment'] == -1])\n",
    "    # Indexes des commentaires positives \n",
    "    positif_indexes = df[df['Sentiment'] == 1].index\n",
    "    # random exempels commentaires positifs\n",
    "    random_indexes = np.random.choice(positif_indexes,no_negatif, replace=False)\n",
    "    # indices des commentaires négatifs\n",
    "    negatif_indexes = df[df['Sentiment'] == -1].index\n",
    "    # Concat les indices trouvés des commentaires postifs & négatifs\n",
    "    underSample_indexes = np.concatenate([negatif_indexes,random_indexes])\n",
    "    # Construire un DataFrame équilibré \n",
    "    df_underSample = df.loc[underSample_indexes]\n",
    "    \n",
    "    # Affection des targer value_y et feature_set X\n",
    "    if method == \"stem\":\n",
    "        X, y = df_underSample.StemmedComments, df_underSample.Sentiment   \n",
    "    if method == \"lem\":\n",
    "        X, y = df_underSample.LemmatizedComments, df_underSample.Sentiment\n",
    "    \n",
    "    # Split the data : train and Test set \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_fonction_avec_gridsearch(classifier, vectorizer):\n",
    "    #  Paramètres GridSerach pour les vectorizers (Count and TFIDF)\n",
    "    parameters_vect = {\n",
    "        'vectorizer__max_df': [0.5, 0.75, 1.0],\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
    "        'vectorizer__max_features': [2000, 4000, 6000]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # paramètres GridSearch pour les Classifieurs \n",
    "    if classifier == \"log\":\n",
    "        parameters_clf = {\"classifier__C\":[0.01,0.1, 1, 10, 100],\n",
    "                          \"classifier__penalty\":['l1', 'l2']}  \n",
    "    elif classifier == \"rf\":\n",
    "        parameters_clf = {'classifier__n_estimators' : [10, 50, 100,200,500],\n",
    "                          'classifier__max_features': ['auto', 'log2'], \n",
    "                          'classifier__criterion' :['gini', 'entropy']} \n",
    "    elif classifier == \"svm\" : \n",
    "        parameters_clf = {'classifier__kernel': ['linear', 'rbf'],\n",
    "                          'classifier__C':[0.01,0.1, 1, 10, 100], \n",
    "                          'classifier__gamma' : [0.01, 0.001, 0.0001]}\n",
    "    else : \n",
    "        return \"Le classifieur spécifié n'est pas traité !\"\n",
    "    \n",
    "    \n",
    "    # définition du vectorizer \n",
    "    if vectorizer == 'tfidf' : \n",
    "        vect =  TfidfVectorizer()\n",
    "    elif vectorizer =='count' : \n",
    "        vect = CountVectorizer()\n",
    "    else :\n",
    "        return \"Le vectorizer spécifié n'est pas traité !\"\n",
    "    \n",
    "    \n",
    "    # définition du classifier \n",
    "    if classifier == \"log\": \n",
    "        clf = LogisticRegression()\n",
    "    elif classifier == \"rf\":\n",
    "        clf = RandomForestClassifier()\n",
    "    elif classifier == \"svm\" : \n",
    "        clf = SVC() \n",
    "    else : \n",
    "        return \"Le classifieur spécifié n'est pas traité !\"\n",
    "    \n",
    "    \n",
    "    # Création du Pipeline\n",
    "    # L'attribut \"memory\" permet d'activer la mise en cache des transformateurs du pipeline (CountVect/TFIDF) dans le dossier spécifié \n",
    "    # le tranformateur n'est pas calculé/entrainé à chaque fois, si les paramètres et les données d'entrée sont identiques (optimisation du temps de calcul)   \n",
    "    print(\"Crération du pipeline avec le classifieur %s ...\" % classifier)\n",
    "    sentiment_pipeline = Pipeline([\n",
    "        ('vectorizer', vect),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Constuire l'objet GridSearchCV \n",
    "    # Définition de la liste compète des paramèters (hyperparamètres) de la GridSearchCV\n",
    "    gridParameters = dict()\n",
    "    gridParameters.update(parameters_vect)\n",
    "    gridParameters.update(parameters_clf)\n",
    "    \n",
    "    \n",
    "    # Création de l'objet GridSearch Associé \n",
    "    # P.S : n_jobs (nbre de processus à exécuter en parallèle ; n_jobs = -1 --> utiliser tous les processus du PC si celui-ci le permet)\n",
    "    # P.S: Score d'évaluation \"roc_auc\" pour prendre en compte le taux de faux postifs, en plus du taux des vrais positifs\n",
    "    #      --> Vue que le DataSet est déséquilibrée, cette métrique est mieux conseillée que l'accuracy pour la compraison des perf des algos. \n",
    "    # verbose = 1: pour afficher quelques message --> permet le suivi de l'avancement de l'algo\n",
    "    gs = RandomizedSearchCV(sentiment_pipeline, param_distributions=gridParameters, verbose=1, cv=7, n_jobs=-1)\n",
    "\n",
    "    # return l'objet GridSearch\n",
    "    return gs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier CSV contenant la DataSet à traiter \n",
    "#dataFile = 'all_reviews_Fr_Prepared_binaryClass.csv'  # Commentaires Français\n",
    "dataFile = 'all_reviews_En_Prepared_binaryClass.csv'  # Commentaires Anglais\n",
    "\n",
    "# Load & Split the Data \n",
    "# Sous_échantillonnage équilibré de commentaires stemmatisés ou lemmatisés \n",
    "X_train_stem, X_test_stem, y_train_stem, y_test_stem = train_test_split_fonction(\"stem\", dataFile)\n",
    "\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split_fonction(\"lem\", dataFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crération du pipeline avec le classifieur rf ...\n",
      "Crération du pipeline avec le classifieur rf ...\n",
      "Crération du pipeline avec le classifieur log ...\n",
      "Crération du pipeline avec le classifieur log ...\n",
      "Crération du pipeline avec le classifieur svm ...\n",
      "Crération du pipeline avec le classifieur svm ...\n",
      "Crération du pipeline avec le classifieur rf ...\n",
      "Crération du pipeline avec le classifieur rf ...\n",
      "Crération du pipeline avec le classifieur log ...\n",
      "Crération du pipeline avec le classifieur log ...\n",
      "Crération du pipeline avec le classifieur svm ...\n",
      "Crération du pipeline avec le classifieur svm ...\n"
     ]
    }
   ],
   "source": [
    "# On va comparer la performance de 4 algorithmes ML différents connus pour l'analyse du Texte (logisticRegression; RandomForest; SVM; NaiveBayes)\n",
    "# Pour chaque algorithme , on fera appel à GridSearch pour optimiser ses hyperparamétres\n",
    "# Et cela dans les deux cas de traitement de texte : Stemming & Lemmatization et les deux vectorizers utilisés  \n",
    "\n",
    "# Création des différents pipelines nécéssaires \n",
    "# Avec Stemming\n",
    "gs_stem_count_rf = pipeline_fonction_avec_gridsearch('rf', 'count')\n",
    "gs_stem_tfidf_rf = pipeline_fonction_avec_gridsearch('rf', 'tfidf')\n",
    "gs_stem_count_log = pipeline_fonction_avec_gridsearch('log', 'count')\n",
    "gs_stem_tfidf_log = pipeline_fonction_avec_gridsearch('log', 'tfidf')\n",
    "gs_stem_count_svm = pipeline_fonction_avec_gridsearch('svm', 'count')\n",
    "gs_stem_tfidf_svm = pipeline_fonction_avec_gridsearch('svm', 'tfidf')\n",
    "# Avec lemmatization \n",
    "gs_lem_count_rf = pipeline_fonction_avec_gridsearch('rf', 'count')\n",
    "gs_lem_tfidf_rf = pipeline_fonction_avec_gridsearch('rf', 'tfidf')\n",
    "gs_lem_count_log = pipeline_fonction_avec_gridsearch('log', 'count')\n",
    "gs_lem_tfidf_log = pipeline_fonction_avec_gridsearch('log', 'tfidf')\n",
    "gs_lem_count_svm = pipeline_fonction_avec_gridsearch('svm', 'count')\n",
    "gs_lem_tfidf_svm = pipeline_fonction_avec_gridsearch('svm', 'tfidf')\n",
    "\n",
    "# Enregsitrement des pipelines dans une liste pour automatiser les itérations\n",
    "grids = [ gs_stem_count_rf,\n",
    "         gs_stem_tfidf_rf,\n",
    "         gs_stem_count_log, \n",
    "         gs_stem_tfidf_log,\n",
    "         gs_stem_count_svm,\n",
    "         gs_stem_tfidf_svm,  \n",
    "         gs_lem_count_rf,\n",
    "         gs_lem_tfidf_rf,\n",
    "         gs_lem_count_log,\n",
    "         gs_lem_tfidf_log,\n",
    "         gs_lem_count_svm,\n",
    "         gs_lem_tfidf_svm\n",
    "        ]\n",
    "\n",
    "# Dictionnaire des pipelines et des types de classificateurs pour faciliter le référencement \n",
    "grid_dict = {0: 'Stemming - Random Forest/Countvectorizer',\n",
    "             1: 'Stemming - Random Forest/TFIDF Vectorizer',\n",
    "             2: 'Stemming - Logistic Regression/Countvectorizer',\n",
    "             3: 'Stemming - Logistic Regression/TFIDF Vectorizer', \n",
    "             4: 'Stemming - Support Vector Machine/Countvectorizer',\n",
    "             5: 'Stemming - Support Vector Machine/TFIDF Vectorizer',\n",
    "             6: 'Lemmatization - Random Forest/Countvectorizer',\n",
    "             7: 'Lemmatization - Random Forest/TFIDF Vectorizer',\n",
    "             8: 'Lemmatization - Logistic Regression/Countvectorizer',\n",
    "             9: 'Lemmatization - Logistic Regression/TFIDF Vectorizer', \n",
    "             10: 'Lemmatization - Support Vector Machine/Countvectorizer',\n",
    "             11: 'Lemmatization - Support Vector Machine/TFIDF Vectorizer'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Optimisation des Modèles ML et Réglages des Hyperparamètres ....**********\n",
      "\n",
      " Nouvelle instane GridSearch...\n",
      "Pipeline : Stemming - Random Forest/Countvectorizer\n",
      "------------------------------------------------\n",
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed: 61.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement SearchGrid faut 4209.1639\n",
      "Meilleur Score CV d'entrainement (accuracy): 0.9096\n",
      "Meilleur ensemble de paramètres: {'vectorizer__ngram_range': (1, 2), 'vectorizer__max_features': 6000, 'vectorizer__max_df': 1.0, 'classifier__n_estimators': 500, 'classifier__max_features': 'log2', 'classifier__criterion': 'entropy'}\n",
      "Score AUC ROC  sur les données de Test avec le meilleur pipeline : 0.9057 \n",
      "\n",
      "\n",
      "Matrice de Confusion :\n",
      "[[11852  1398]\n",
      " [ 1101 12149]]\n",
      "Rapport de Classification sur les donénes de Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.89      0.90     13250\n",
      "           1       0.90      0.92      0.91     13250\n",
      "\n",
      "    accuracy                           0.91     26500\n",
      "   macro avg       0.91      0.91      0.91     26500\n",
      "weighted avg       0.91      0.91      0.91     26500\n",
      "\n",
      "\n",
      " Nouvelle instane GridSearch...\n",
      "Pipeline : Stemming - Random Forest/TFIDF Vectorizer\n",
      "------------------------------------------------\n",
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 76.2min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed: 135.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement SearchGrid faut 8589.3133\n",
      "Meilleur Score CV d'entrainement (accuracy): 0.9055\n",
      "Meilleur ensemble de paramètres: {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_features': 2000, 'vectorizer__max_df': 0.75, 'classifier__n_estimators': 500, 'classifier__max_features': 'log2', 'classifier__criterion': 'entropy'}\n",
      "Score AUC ROC  sur les données de Test avec le meilleur pipeline : 0.9008 \n",
      "\n",
      "\n",
      "Matrice de Confusion :\n",
      "[[11819  1431]\n",
      " [ 1198 12052]]\n",
      "Rapport de Classification sur les donénes de Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.89      0.90     13250\n",
      "           1       0.89      0.91      0.90     13250\n",
      "\n",
      "    accuracy                           0.90     26500\n",
      "   macro avg       0.90      0.90      0.90     26500\n",
      "weighted avg       0.90      0.90      0.90     26500\n",
      "\n",
      "\n",
      " Nouvelle instane GridSearch...\n",
      "Pipeline : Stemming - Logistic Regression/Countvectorizer\n",
      "------------------------------------------------\n",
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement SearchGrid faut 256.4257\n",
      "Meilleur Score CV d'entrainement (accuracy): 0.9110\n",
      "Meilleur ensemble de paramètres: {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_features': 6000, 'vectorizer__max_df': 0.75, 'classifier__penalty': 'l2', 'classifier__C': 0.01}\n",
      "Score AUC ROC  sur les données de Test avec le meilleur pipeline : 0.9094 \n",
      "\n",
      "\n",
      "Matrice de Confusion :\n",
      "[[11899  1351]\n",
      " [ 1051 12199]]\n",
      "Rapport de Classification sur les donénes de Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.90      0.91     13250\n",
      "           1       0.90      0.92      0.91     13250\n",
      "\n",
      "    accuracy                           0.91     26500\n",
      "   macro avg       0.91      0.91      0.91     26500\n",
      "weighted avg       0.91      0.91      0.91     26500\n",
      "\n",
      "\n",
      " Nouvelle instane GridSearch...\n",
      "Pipeline : Stemming - Logistic Regression/TFIDF Vectorizer\n",
      "------------------------------------------------\n",
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement SearchGrid faut 339.9396\n",
      "Meilleur Score CV d'entrainement (accuracy): 0.9137\n",
      "Meilleur ensemble de paramètres: {'vectorizer__ngram_range': (1, 3), 'vectorizer__max_features': 2000, 'vectorizer__max_df': 0.75, 'classifier__penalty': 'l2', 'classifier__C': 1}\n",
      "Score AUC ROC  sur les données de Test avec le meilleur pipeline : 0.9114 \n",
      "\n",
      "\n",
      "Matrice de Confusion :\n",
      "[[11968  1282]\n",
      " [ 1067 12183]]\n",
      "Rapport de Classification sur les donénes de Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.90      0.91     13250\n",
      "           1       0.90      0.92      0.91     13250\n",
      "\n",
      "    accuracy                           0.91     26500\n",
      "   macro avg       0.91      0.91      0.91     26500\n",
      "weighted avg       0.91      0.91      0.91     26500\n",
      "\n",
      "\n",
      " Nouvelle instane GridSearch...\n",
      "Pipeline : Stemming - Support Vector Machine/Countvectorizer\n",
      "------------------------------------------------\n",
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search objects\n",
    "print('********* Optimisation des Modèles ML et Réglages des Hyperparamètres ....**********')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "\n",
    "# Boucle pour l'évaluation de tous les pipelines (enregistrement du meilleure Classifieur pour chaque pipeline )\n",
    "for idx, gs in enumerate(grids) : \n",
    "    \n",
    "    print(\"\\n Nouvelle instane GridSearch...\")\n",
    "    print('Pipeline : %s' % grid_dict[idx])\n",
    "    print('------------------------------------------------')\n",
    "    # Entrainement du Grid Search sur le data_train\n",
    "    t0 = time()\n",
    "    if (grid_dict[idx][0:3]=='Lem'): # fit on the LemmatizedComments\n",
    "        gs.fit(X_train_lem, y_train_lem)\n",
    "    else : \n",
    "        gs.fit(X_train_stem, y_train_stem)\n",
    "    print(\"Entrainement SearchGrid faut %0.4f\" % (time() - t0))\n",
    "    # Meilleur pipeline \n",
    "    best_pipe = gs.best_estimator_\n",
    "    # Meilleur paramètres et score \n",
    "    print('Meilleur Score CV d\\'entrainement (accuracy): %.4f' % gs.best_score_)   \n",
    "    print('Meilleur ensemble de paramètres: %s' % gs.best_params_)\n",
    "    # Prédire les donnes de Test avec le meilleur classifieur\n",
    "    if (grid_dict[idx][0:3]=='Lem'): # fit on the LemmatizedComments\n",
    "        y_pred = best_pipe.predict(X_test_lem)\n",
    "        acc_score = accuracy_score(y_test_lem, y_pred)\n",
    "        print('Score \"accuracy\" ur les données de Test avec le meilleur pipeline : %0.4f ' % acc_score )\n",
    "        print('\\n')\n",
    "         # Afficher d'autres métriques significatives\n",
    "        #print('Score \"Accuracy\" sur les données de Test avec le meilleur pipeline : %0.4f ' % accuracy_score(y_test_lem, y_pred) )\n",
    "        print('Matrice de Confusion :')\n",
    "        print(confusion_matrix(y_test_lem, y_pred))\n",
    "        print(\"Rapport de Classification sur les donénes de Test\")\n",
    "        print(classification_report(y_test_lem,y_pred))   \n",
    "    else :\n",
    "        y_pred = best_pipe.predict(X_test_stem)\n",
    "        acc_score = accuracy_score(y_test_stem, y_pred)\n",
    "        print('Score AUC ROC  sur les données de Test avec le meilleur pipeline : %0.4f ' % acc_score )\n",
    "        print('\\n')\n",
    "        # Afficher d'autres métriques significatives\n",
    "        #print('Score \"Accuracy\" sur les données de Test avec le meilleur pipeline : %0.4f ' % accuracy_score(y_test_stem, y_pred) )\n",
    "        print('Matrice de Confusion :')\n",
    "        print(confusion_matrix(y_test_stem, y_pred))\n",
    "        print(\"Rapport de Classification sur les donénes de Test\")\n",
    "        print(classification_report(y_test_stem,y_pred))\n",
    "    \n",
    "    #  Suivi du meilleur modèle (AUC ROC la plus élevée)\n",
    "    if acc_score > best_acc: \n",
    "        best_acc = acc_score\n",
    "        best_gs = gs \n",
    "        best_clf = idx \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix du Meilleur Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8532c4c4f5a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n Le Modèle avec les meilleurs performances est: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Enregistrer le meilleur pipeline de GridSearch dans un fichier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdump_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'best_gs_pipeline.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_gs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\n Le Modèle avec les meilleurs performances est: %s' % grid_dict[best_clf])\n",
    "\n",
    "# Enregistrer le meilleur pipeline de GridSearch dans un fichier \n",
    "dump_file = 'best_gs_pipeline.pkl'\n",
    "joblib.dump(best_gs, dump_file, compress=1)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], dump_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHOIX ET CHARGEMENT DU MODELE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir choisi notre modèle ainsi que les parameteres les plus optimals, il faut entrainer ce modèle sur toute la base puis sauvegarder le modèle sous forme de fichier .pkl grace au module pickle de Python.\n",
    "Pickle sert a serialiser, soit convertir une hiérarichie d'obtejts Python en un flux d'octet. Un tel fichier peut donc passer par le \"unpickling\" pour pouvoir permettre de manipuler le modèle en  python depuis un fihcir de flux d'octet.\n",
    "Cette étape est indispensable dans la mesure où le but de se projet et d'exposer un modèle ML. On aurait pu entrainer ce modèle dès que l'uilsatuer rentrerait un commentaire à analyser, mais cela serait bcp trop long et innaproprié. Pour cela il est donc indispensable d'enregistrer le modèle afin de deployer facilement un modèle de machine learning sur une interface (pour nous il s'agit d'un site web utilsant la librairie pytho FLASK)\n",
    "imaginons qu'il s'avere que log regression ait obtneu les meilleur score avec un tfidf sans lem ni stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/04/how-to-deploy-machine-learning-model-flask/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mettre à jour cette partie une fois l'entrainement et la comparasion des modèle est terminé\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv('all_reviews_EN_Prepared_binaryClass.csv',sep=';')\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    mon_modele = open(\"modele_en_description.txt\", \"w\") # Argh j'ai tout écrasé !\n",
    "    mod = \"Tfidf/Stem/Log {'classifier__C': 1, 'classifier__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 3)}\"\n",
    "    mon_modele.write(mod)\n",
    "    mon_modele.close()\n",
    "    \n",
    "    X, y = df.StemmedComments, df.Sentiment\n",
    "    #a modifier\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,3),max_df=0.75,max_features=2000)\n",
    "    #a modifier avec les patrametress\n",
    "    \n",
    "    classifier =  LogisticRegression(C=1,penalty='l2')\n",
    "   \n",
    "    sentiment_pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier',classifier)\n",
    "    ])\n",
    "    \n",
    "    #fiting model with  training data\n",
    "    sentiment_pipeline.fit(X,y)\n",
    "    \n",
    "    #saving model to disk\n",
    "    pickle.dump(sentiment_pipeline, open('app/model_en.pkl','wb'))\n",
    "    \n",
    "    #loading model to compare the result\n",
    "    model_fr = pickle.load(open('app/model_en.pkl','rb'))\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 189735 entries, 0 to 189734\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   Commentaire         189735 non-null  object\n",
      " 1   Sentiment           189735 non-null  int64 \n",
      " 2   StemmedComments     189735 non-null  object\n",
      " 3   LemmatizedComments  189735 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 5.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 189735 entries, 0 to 189734\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   Commentaire         189735 non-null  object\n",
      " 1   Sentiment           189735 non-null  int64 \n",
      " 2   StemmedComments     189735 non-null  object\n",
      " 3   LemmatizedComments  189735 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 5.8+ MB\n",
      "None\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-be02614deb6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vide\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-c9c4b5a55cc4>\u001b[0m in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m#fiting model with  training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0msentiment_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m#saving model to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.2020\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3.2020\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.2020\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.2020\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.2020\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \"\"\"\n\u001b[0;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1841\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.2020\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1218\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m                                                        max_features)\n\u001b[0m\u001b[0;32m   1221\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.2020\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[1;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m                 \u001b[0mremoved_terms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "df = df.fillna(\"vide\")\n",
    "print(df.info())\n",
    "load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test prediction grace au model chargé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "import spacy\n",
    "from spacy_lefff import LefffLemmatizer, POSTagger\n",
    "\n",
    "\n",
    "model_fr = pickle.load(open('app/model_fr.pkl','rb'))\n",
    "\n",
    "\n",
    "\n",
    "#si ni lemm ni stemm\n",
    "#text = [\"bravo\"]\n",
    "\n",
    "#si stemm\n",
    "text = \"honte\"\n",
    "FrenchStemmer = SnowballStemmer(\"french\")\n",
    "wt = word_tokenize(text)\n",
    "st = [FrenchStemmer.stem(token) for token in wt ]\n",
    "st = ' '.join(st)\n",
    "text = [st]\n",
    "\n",
    "\n",
    "#si lemm\n",
    "\"\"\"\n",
    "text = \"hontes\"\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "french_lemmatizer = LefffLemmatizer()\n",
    "nlp.add_pipe(french_lemmatizer, name='lefff')\n",
    "doc = nlp(text)   \n",
    "lt=''\n",
    "for d in doc:\n",
    "    #print(d.text, d.pos_, d._.lefff_lemma, d.tag_, d.lemma_)\n",
    "    lt = lt + \" \" + d.lemma_\n",
    "text = [lt]\n",
    "\"\"\"\n",
    "# predict the label using the pipeline\n",
    "print(str(model_fr.predict(text)[0]))\n",
    "\n",
    "\n",
    "proba = model_fr.predict_proba(text)[0]\n",
    "proba_neg = proba[0]\n",
    "proba_pos = proba[-1]\n",
    "print(proba_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
